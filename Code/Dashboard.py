import streamlit as st
import pandas as pd
import json
import os
import plotly.express as px
import sys
from preposesing import generate_ai_summary_for_category
import pandas as pd
import re
from io import StringIO
import contextlib
from Crawling import (
    initialize_driver, search_movie_by_title, scrape_all_reviews,get_movie_reviews_by_title)

from preposesing import (
    clean_text, generate_wordcloud, categorize_sentiment, extract_common_phrases)


# Set page configuration
st.set_page_config(
    page_title="IMDb Review Scraper",
    page_icon="üé¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styling
st.markdown("""
<style>
.title {
    font-size: 42px !important;
    color: #F5C518;
    text-align: center;
}
.subtitle {
    font-size: 24px !important;
    color: #E2B616;
    text-align: center;
}
.stProgress > div > div > div > div {
    background-color: #F5C518;
}
.review-card {
    background-color: #f0f2f6;
    border-radius: 10px;
    padding: 20px;
    margin-bottom: 20px;
}
.review-title {
    font-weight: bold;
    font-size: 18px;
    margin-bottom: 10px;
}
.review-rating {
    color: #F5C518;
    font-weight: bold;
}
.review-text {
    font-style: italic;
    color: #333;
}
.review-author {
    text-align: right;
    font-size: 14px;
    color: #666;
}
.review-date {
    text-align: right;
    font-size: 12px;
    color: #888;
}
</style>
""", unsafe_allow_html=True)

# Title and description
st.markdown("<h1 class='title'>IMDb Review Scraper Dashboard</h1>", unsafe_allow_html=True)
st.markdown("<p class='subtitle'>Search for movies and analyze their reviews</p>", unsafe_allow_html=True)


# Safe execution function to capture output
@contextlib.contextmanager
def capture_output():
    old_stdout = sys.stdout
    old_stderr = sys.stderr
    stdout_buffer = StringIO()
    stderr_buffer = StringIO()
    sys.stdout = stdout_buffer
    sys.stderr = stderr_buffer
    try:
        yield stdout_buffer, stderr_buffer
    finally:
        sys.stdout = old_stdout
        sys.stderr = old_stderr

# Initialize session state
if 'search_results' not in st.session_state:
    st.session_state.search_results = None
if 'selected_movie' not in st.session_state:
    st.session_state.selected_movie = None
if 'reviews_data' not in st.session_state:
    st.session_state.reviews_data = None
if 'driver' not in st.session_state:
    st.session_state.driver = None
if 'loading' not in st.session_state:
    st.session_state.loading = False

# Create sidebar for search and options
with st.sidebar:
    st.header("Search Options")
    
    # Movie search
    movie_title = st.text_input("Enter movie title:")
    max_pages = st.number_input("Maximum pages to scrape (0 for all):", min_value=0, value=2)
    if max_pages == 0:
        max_pages = None
    
    # Search button
    if st.button("Search Movies"):
        if movie_title:
            st.session_state.loading = True

            # Initialize driver
            if not st.session_state.driver:
                with st.spinner("Initializing browser..."):
                    with capture_output() as (stdout, stderr):
                        try:
                            st.session_state.driver = initialize_driver()
                        except Exception as e:
                            st.error(f"Error initializing browser: {str(e)}")
                            st.session_state.loading = False
            
            # Search for movies
            if st.session_state.driver:
                with st.spinner(f"Searching for '{movie_title}'..."):
                    with capture_output() as (stdout, stderr):
                        try:
                            st.session_state.search_results = search_movie_by_title(movie_title, st.session_state.driver)
                        except Exception as e:
                            st.error(f"Error searching for movie: {str(e)}")
                    st.session_state.loading = False
        else:
            st.warning("Please enter a movie title")


# Display search results and let user select a movie
if st.session_state.search_results and not st.session_state.loading:
    st.header("Search Results")
    col1, col2 = st.columns([3, 1])
    
    with col1:
        # Display movies as compact cards with smaller images
        # Use 3 cards per row
        movies_per_row = 3
        rows = [st.session_state.search_results[i:i+movies_per_row] 
                for i in range(0, len(st.session_state.search_results), movies_per_row)]
        
        for row in rows:
            cols = st.columns(movies_per_row)
            
            for i, (col, movie) in enumerate(zip(cols, row)):
                idx = rows.index(row) * movies_per_row + i  # Calculate global index
                
                with col:
                    # Display movie poster if available
                    if movie.get('image_url'):
                        st.image(movie['image_url'], width=80)
                    else:
                        # Display placeholder if no image available
                        st.markdown("üìΩÔ∏è")
                    
                    # Add title with smaller font
                    st.markdown(f"**{movie['title']}** ({movie['year']})")
                    
                    # Streamlined ID display
                    st.caption(f"ID: {movie['imdb_id']}")
                    
                    # More compact button
                    if st.button(f"Select", key=f"select_{idx}", use_container_width=True):
                        st.session_state.selected_movie = movie
                        st.session_state.selected_index = idx
                        # Force rerun to trigger the automatic scraping
                        st.rerun()
    
    with col2:
        st.subheader("Selected Movie")
        
        # Check if selected_movie exists and is not None
        if hasattr(st.session_state, 'selected_movie') and st.session_state.selected_movie is not None:
            selected_movie = st.session_state.selected_movie
            
            # Display selected movie poster
            if selected_movie.get('image_url'):
                st.image(selected_movie['image_url'], width=150)
            
            st.markdown(f"**{selected_movie['title']}** ({selected_movie['year']})")
            st.text(f"IMDb ID: {selected_movie['imdb_id']}")
            
            # Automatic scraping when movie is selected (happens only once per selection)
            if not hasattr(st.session_state, 'last_scraped_id') or st.session_state.last_scraped_id != selected_movie['imdb_id']:
                st.session_state.last_scraped_id = selected_movie['imdb_id']
                st.session_state.loading = True
                
                # Scrape reviews for selected movie
                with st.spinner(f"Scraping reviews for '{selected_movie['title']}'..."):
                    try:
                        with capture_output() as (stdout, stderr):
                            imdb_id = selected_movie['imdb_id']
                            st.session_state.reviews_data = scrape_all_reviews(
                                imdb_id, 
                                st.session_state.driver, 
                                max_pages
                            )
                        
                        # Save to file
                        os.makedirs("reviews", exist_ok=True)
                        sanitized_title = re.sub(r'[\\/*?:"<>|]', "", 
                                               selected_movie['title'].replace(' ', '_'))
                        filename = f"reviews/reviews_{imdb_id}_{sanitized_title}.json"
                        with open(filename, 'w', encoding='utf-8') as json_file:
                            json.dump(st.session_state.reviews_data, json_file, ensure_ascii=False, indent=4)
                        
                        # Notify user that scraping is complete
                        st.success(f"Scraped {len(st.session_state.reviews_data['reviews'])} reviews!")
                    
                    except Exception as e:
                        st.error(f"Error scraping reviews: {str(e)}")
                    
                    st.session_state.loading = False
        else:
            st.markdown("*Please select a movie from the list*")

# Alternative version with table layout
def display_results_as_table():
    # Create a DataFrame for display
    df_results = pd.DataFrame([
        {
            "Title": movie['title'],
            "Year": movie['year'],
            "IMDb ID": movie['imdb_id'],
            "Image": movie.get('image_url', "")  # Include image URL in DataFrame
        } for movie in st.session_state.search_results
    ])
    
    # Display as table
    st.dataframe(
        df_results,
        column_config={
            "Image": st.column_config.ImageColumn(
                "Poster", help="Movie poster image"
            )
        },
        use_container_width=True,
        hide_index=True
    )
    
    # Selection dropdown
    selected_index = st.selectbox(
        "Select a movie:",
        options=range(len(st.session_state.search_results)),
        format_func=lambda x: f"{st.session_state.search_results[x]['title']} ({st.session_state.search_results[x]['year']})"
    )
    
    if selected_index is not None:
        st.session_state.selected_movie = st.session_state.search_results[selected_index]
        st.session_state.selected_index = selected_index

# Display and analyze reviews if available

if st.session_state.reviews_data and not st.session_state.loading:
    reviews = st.session_state.reviews_data['reviews']
    movie_info = st.session_state.selected_movie
    
    st.header(f"Reviews Analysis: {movie_info['title']} ({movie_info['year']})")
    st.subheader(f"Found {len(reviews)} reviews")
    
    # Create dataframe from reviews
    review_data = []
    for review in reviews:
        review_data.append({
            'short_review': review.get('short_review', 'No title'),
            'full_review': review.get('full_review', 'No content'),
            'rating': review.get('rating_value', 'Unknown'),
            'reviewer': review.get('reviewer_name', 'Anonymous'),
            'date': review.get('review_date', 'Unknown date'),
            'sentiment': analyze_sentiment(review.get('full_review', ''))
        })
    
    df_reviews = pd.DataFrame(review_data)
    
    # Analytics tabs
    tab1, tab2, tab3, tab4, tab5= st.tabs(["Overview", "Review Text Analysis", "Sentiment Analysis", "Reasoning Review","Raw Data"])
    
    with tab1:
        # Overview stats
        col1, col2, col3 = st.columns(3)
        
        with col1:
            # Rating distribution
            ratings = df_reviews['rating'].dropna()
            if len(ratings) > 0:
                try:
                    ratings = ratings.astype(float)
                    avg_rating = ratings.mean()
                    st.metric("Average Rating", f"{avg_rating:.1f}/10")
                    
                    # Rating distribution chart
                    fig_rating = px.histogram(
                        df_reviews, 
                        x='rating',
                        nbins=10,
                        title="Rating Distribution",
                        color_discrete_sequence=['#F5C518']
                    )
                    fig_rating.update_layout(
                        xaxis=dict(
                            range=[1, 10], 
                            tickvals=list(range(1, 11)),
                            tickmode='array',  # Ensures exact tick placement
                            tickformat='.0f'   # Forces integer display
                        )
                    )

                    st.plotly_chart(fig_rating, use_container_width=True)
                except:
                    st.warning("Could not analyze ratings (possible format issues)")
            else:
                st.warning("No rating data available")
        
        with col2:
            # Sentiment distribution
            sentiment_counts = df_reviews['sentiment'].value_counts()
            fig_sentiment = px.pie(
                names=sentiment_counts.index,
                values=sentiment_counts.values,
                title="Review Sentiment Distribution",
                color=sentiment_counts.index,
                color_discrete_map={
                    'Positive': '#4CAF50',
                    'Neutral': '#FFC107',
                    'Negative': '#F44336',
                }
            )
            fig_sentiment.update_traces(textposition='inside', textinfo='percent+label')
            st.plotly_chart(fig_sentiment, use_container_width=True)
        
        with col3:
            # Review date trend if available
            if 'date' in df_reviews.columns:
                # Try to convert date strings to datetime
                try:
                    # Extract year from date strings using regex
                    df_reviews['year'] = df_reviews['date'].str.extract(r'(\d{4})')
                    year_counts = df_reviews['year'].value_counts().sort_index()
                    
                    if not year_counts.empty:
                        fig_trend = px.bar(
                            x=year_counts.index,
                            y=year_counts.values,
                            title="Reviews by Year",
                            labels={'x': 'Year', 'y': 'Number of Reviews'},
                            color_discrete_sequence=['#1f77b4']
                        )
                        st.plotly_chart(fig_trend, use_container_width=True)
                except:
                    st.warning("Could not analyze review dates")
        
        # Sample reviews
        st.subheader("Sample Reviews")
        
        # Sort by rating if available
        if 'rating' in df_reviews.columns:
            try:
                df_sorted = df_reviews.copy()
                df_sorted['rating_numeric'] = pd.to_numeric(df_sorted['rating'], errors='coerce')
                df_sorted = df_sorted.sort_values('rating_numeric', ascending=False)
                sample_reviews = df_sorted.head(5).to_dict('records')
            except:
                sample_reviews = df_reviews.head(5).to_dict('records')
        else:
            sample_reviews = df_reviews.head(5).to_dict('records')
        
        # Display sample reviews
        for i, review in enumerate(sample_reviews):
            with st.container():
                st.markdown(f"""
                <div class="review-card">
                    <div class="review-title">{review['short_review']}</div>
                    <div class="review-rating">Rating: {review['rating']}/10</div>
                    <div class="review-text">{review['full_review'][:300]}{'...' if len(review['full_review']) > 300 else ''}</div>
                    <div class="review-author">By: {review['reviewer']}</div>
                    <div class="review-date">{review['date']}</div>
                </div>
                """, unsafe_allow_html=True)
    
    with tab2:
        # Text analysis
        st.subheader("Word Cloud from Reviews")
        
        # Combine all review text for word cloud
        all_review_text = " ".join([clean_text(review['full_review']) for review in review_data if review['full_review']])
        
        if all_review_text.strip():
            wordcloud_fig = generate_wordcloud(all_review_text)
            st.pyplot(wordcloud_fig)
        else:
            st.warning("No text available for word cloud generation")
        
        # Common phrases
        st.subheader("Most Common Phrases")
        
        common_phrases = extract_common_phrases(reviews)
        if common_phrases:
            phrases_df = pd.DataFrame(common_phrases, columns=['Phrase', 'Count'])
            
            fig_phrases = px.bar(
                phrases_df.head(10),
                x='Count',
                y='Phrase',
                orientation='h',
                title="Most Common Phrases in Reviews",
                color='Count',
                color_continuous_scale='Viridis'
            )
            fig_phrases.update_layout(yaxis={'categoryorder':'total ascending'})
            st.plotly_chart(fig_phrases, use_container_width=True)
        else:
            st.warning("No common phrases found")
    
    with tab3:
        # Sentiment analysis
        st.subheader("Sentiment Analysis")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Sentiment distribution
            sentiment_counts = df_reviews['sentiment'].value_counts()
            
            fig_sent_bar = px.bar(
                x=sentiment_counts.index,
                y=sentiment_counts.values,
                title="Sentiment Distribution",
                labels={'x': 'Sentiment', 'y': 'Count'},
                color=sentiment_counts.index,
                color_discrete_map={
                    'Positive': '#4CAF50',
                    'Neutral': '#FFC107',
                    'Negative': '#F44336',
                }
            )
            st.plotly_chart(fig_sent_bar, use_container_width=True)
        
        with col2:
            # Average rating by sentiment
            try:
                df_reviews['rating_numeric'] = pd.to_numeric(df_reviews['rating'], errors='coerce')
                avg_by_sentiment = df_reviews.groupby('sentiment')['rating_numeric'].mean().reset_index()
                
                fig_avg_sent = px.bar(
                    avg_by_sentiment,
                    x='sentiment',
                    y='rating_numeric',
                    title="Average Rating by Sentiment",
                    labels={'rating_numeric': 'Average Rating', 'sentiment': 'Sentiment'},
                    color='sentiment',
                    color_discrete_map={
                        'Positive': '#4CAF50',
                        'Neutral': '#FFC107',
                        'Negative': '#F44336',
                    }
                )
                st.plotly_chart(fig_avg_sent, use_container_width=True)
            except:
                st.warning("Could not analyze ratings by sentiment")
        
        # Reviews by sentiment
        st.subheader("Sample Reviews by Sentiment")
        
        # Create sentiment filter
        selected_sentiment = st.selectbox(
            "Filter by sentiment:",
            options=['All'] + list(df_reviews['sentiment'].unique())
        )
        
        if selected_sentiment != 'All':
            filtered_reviews = df_reviews[df_reviews['sentiment'] == selected_sentiment]
        else:
            filtered_reviews = df_reviews
        
        # Display filtered reviews
        for i, review in enumerate(filtered_reviews.head(3).to_dict('records')):
            with st.container():
                st.markdown(f"""
                <div class="review-card">
                    <div class="review-title">{review['short_review']}</div>
                    <div class="review-rating">Rating: {review['rating']}/10 ({review['sentiment']})</div>
                    <div class="review-text">{review['full_review'][:300]}{'...' if len(review['full_review']) > 300 else ''}</div>
                    <div class="review-author">By: {review['reviewer']}</div>
                </div>
                """, unsafe_allow_html=True)
    
    
    with tab4:
        st.subheader("Reasoning Summaries Review")
        
        # Create review data for analysis
        reviews_text = [review.get('full_review', '') for review in reviews]
        ratings = [review.get('rating_value', 0) for review in reviews]
        
        # Prepare data for AI summary
        analysis_data = {
            'total': len(reviews),
            'positive': len([r for r in df_reviews['sentiment'] if r == 'Positive']),
            'negative': len([r for r in df_reviews['sentiment'] if r == 'Negative']),
            'positive_pct': f"{len([r for r in df_reviews['sentiment'] if r == 'Positive'])/len(reviews)*100:.1f}",
            'negative_pct': f"{len([r for r in df_reviews['sentiment'] if r == 'Negative'])/len(reviews)*100:.1f}",
            'pos_common': extract_common_phrases([r for r, s in zip(reviews, df_reviews['sentiment']) if s == 'Positive']),
            'neg_common': extract_common_phrases([r for r, s in zip(reviews, df_reviews['sentiment']) if s == 'Negative']),
            'pos_terms': "Terms extracted from positive reviews",
            'neg_terms': "Terms extracted from negative reviews",
            'pos_avg_len': f"{df_reviews[df_reviews['sentiment'] == 'Positive']['full_review'].str.len().mean():.1f}",
            'neg_avg_len': f"{df_reviews[df_reviews['sentiment'] == 'Negative']['full_review'].str.len().mean():.1f}"
        }
        
        # Create tabs for different summaries
        summary_tab1, summary_tab2, summary_tab3 = st.tabs(["Overall Analysis", "Negative Reviews", "Positive Reviews"])
        
        with summary_tab1:
            with st.spinner("Generating overall summary..."):
                positive_summary = generate_ai_summary_for_category(analysis_data, "overall")
                st.subheader("Overall Analysis")
                st.write(positive_summary)
        
        with summary_tab2:
            with st.spinner("Generating positive reviews summary..."):
                negative_summary = generate_ai_summary_for_category(analysis_data, "positive")
                st.subheader("Positive Reviews Summary")
                st.write(negative_summary)
        
        with summary_tab3:
            with st.spinner("Generating negative reviews summary..."):
                overall_summary = generate_ai_summary_for_category(analysis_data, "negative")
                st.subheader("Negative Reviews Summary")
                st.write(overall_summary)
        
        # Display a note about OpenAI API usage
        # st.info("Note: These summaries are generated using OpenAI's API. Make sure you have set your API key in the environment variables for this feature to work properly.")


    with tab5:
        # Raw data display
        st.subheader("Raw Review Data")
        st.dataframe(df_reviews, use_container_width=True)
        
        # Download button
        @st.cache_data
        def convert_df_to_csv(df):
            return df.to_csv(index=False).encode('utf-8')
        
        csv = convert_df_to_csv(df_reviews)
        st.download_button(
            "Download Data as CSV",
            csv,
            f"{movie_info['title']}_{movie_info['imdb_id']}_reviews.csv",
            "text/csv",
            key='download-csv'
        )

# Footer
st.markdown("""
---
<div style='text-align: center'>
    <p>IMDb Review Scraper Dashboard | Built with Streamlit</p>
    <p style='font-size: 12px; color: #888;'>
        This dashboard scrapes data from IMDb for analysis purposes. Please respect IMDb's terms of service.
    </p>
</div>
""", unsafe_allow_html=True)

